{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Test 3 --- Final Test for 06.11.2025"
      ],
      "metadata": {
        "id": "XtOuIKifmmyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[atari,accept-rom-license]\n",
        "!pip install autorom\n",
        "!pip install stable-baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqL9333gml9l",
        "outputId": "c83a5f35-06b7-4fb3-ed21-c4cdd3cd2dd6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "\u001b[33mWARNING: gymnasium 1.2.2 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (0.11.2)\n",
            "Collecting autorom\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from autorom) (8.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from autorom) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->autorom) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->autorom) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->autorom) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->autorom) (2025.11.12)\n",
            "Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Installing collected packages: autorom\n",
            "Successfully installed autorom-0.6.1\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (1.2.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.9.0+cu126)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.3)\n",
            "Downloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!AutoROM --accept-license"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi2qmVoVmxve",
        "outputId": "06cfbc03-b062-4e77-db55-f03b2e94b9bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/usr/local/lib/python3.12/dist-packages/AutoROM/roms\n",
            "\n",
            "Existing ROMs will be overwritten.\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/adventure.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/air_raid.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/alien.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/amidar.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/assault.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/asterix.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/asteroids.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/atlantis.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/atlantis2.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/backgammon.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/bank_heist.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/basic_math.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/battle_zone.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/beam_rider.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/berzerk.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/blackjack.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/bowling.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/boxing.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/breakout.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/carnival.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/casino.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/centipede.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/chopper_command.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/combat.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/crazy_climber.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/crossbow.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/darkchambers.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/defender.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/demon_attack.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/donkey_kong.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/double_dunk.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/earthworld.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/elevator_action.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/enduro.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/entombed.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/et.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/fishing_derby.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/flag_capture.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/freeway.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/frogger.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/frostbite.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/galaxian.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/gopher.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/gravitar.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/hangman.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/haunted_house.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/hero.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/human_cannonball.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/ice_hockey.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/jamesbond.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/journey_escape.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/joust.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/kaboom.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/kangaroo.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/keystone_kapers.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/king_kong.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/klax.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/koolaid.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/krull.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/kung_fu_master.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/laser_gates.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/lost_luggage.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/mario_bros.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/maze_craze.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/miniature_golf.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/montezuma_revenge.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/mr_do.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/ms_pacman.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/name_this_game.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/othello.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pacman.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/phoenix.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pitfall.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pitfall2.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pong.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pooyan.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/private_eye.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/qbert.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/riverraid.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/road_runner.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/robotank.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/seaquest.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/sir_lancelot.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/skiing.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/solaris.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/space_invaders.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/space_war.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/star_gunner.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/superman.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/surround.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/tennis.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/tetris.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/tic_tac_toe_3d.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/time_pilot.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/trondead.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/turmoil.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/tutankham.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/up_n_down.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/venture.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/video_checkers.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/video_chess.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/video_cube.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/video_pinball.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/warlords.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/wizard_of_wor.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/word_zapper.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/yars_revenge.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/zaxxon.bin\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install the Gym"
      ],
      "metadata": {
        "id": "RQyqgMFzT-qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ale_py\n",
        "import gymnasium as gym"
      ],
      "metadata": {
        "id": "_W_afhrzUAnp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure the model save drive"
      ],
      "metadata": {
        "id": "E0n7zQrALq7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v8hSrWrrLibc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb34220-71ff-408a-e9b0-7993729fbbc3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "save_dir = \"/content/drive/MyDrive/PUBLIC/Models\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "vlWPUjKfLv9y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now Model"
      ],
      "metadata": {
        "id": "SAEvyoukL1T3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "import argparse\n",
        "import time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import collections\n",
        "import typing as tt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.tensorboard.writer import SummaryWriter"
      ],
      "metadata": {
        "id": "VCbjkLLSxCUN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dqn_model\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_shape, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        size = self.conv(torch.zeros(1, *input_shape)).size()[-1]\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, n_actions)\n",
        "        )\n",
        "    def forward(self, x: torch.ByteTensor):\n",
        "        x = x.float() / 255.0\n",
        "        return self.fc(self.conv(x))"
      ],
      "metadata": {
        "id": "dIJ32Rs6xJsV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wrappers\n",
        "\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3.common import atari_wrappers\n",
        "\n",
        "\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    ImageToPyTorch: Reorders image dimensions from (H, W, C) to (C, H, W)\n",
        "    for compatibility with PyTorch convolutional layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, env):\n",
        "        super(ImageToPyTorch, self).__init__(env)\n",
        "        obs = self.observation_space\n",
        "        assert isinstance(obs, gym.spaces.Box)\n",
        "        assert len(obs.shape) == 3\n",
        "        new_shape = (obs.shape[-1], obs.shape[0], obs.shape[1])\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=obs.low.min(), high=obs.high.max(),\n",
        "            shape=new_shape, dtype=obs.dtype)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.moveaxis(observation, 2, 0)\n",
        "\n",
        "\n",
        "class BufferWrapper(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    BufferWrapper: Maintains a rolling window of the last `n_steps` frames\n",
        "    to give the agent a sense of temporal context.\n",
        "    \"\"\"\n",
        "    def __init__(self, env, n_steps):\n",
        "        super(BufferWrapper, self).__init__(env)\n",
        "        obs = env.observation_space\n",
        "        assert isinstance(obs, spaces.Box)\n",
        "        new_obs = gym.spaces.Box(\n",
        "            obs.low.repeat(n_steps, axis=0), obs.high.repeat(n_steps, axis=0),\n",
        "            dtype=obs.dtype)\n",
        "        self.observation_space = new_obs\n",
        "        self.buffer = collections.deque(maxlen=n_steps)\n",
        "\n",
        "    def reset(self, *, seed: tt.Optional[int] = None, options: tt.Optional[dict[str, tt.Any]] = None):\n",
        "        for _ in range(self.buffer.maxlen):\n",
        "            self.buffer.append(np.zeros_like(self.env.observation_space.low))\n",
        "        obs, extra = self.env.reset()\n",
        "        return self.observation(obs), extra\n",
        "\n",
        "    def observation(self, observation: np.ndarray) -> np.ndarray:\n",
        "        self.buffer.append(observation)\n",
        "        return np.concatenate(self.buffer)\n",
        "\n",
        "\n",
        "def make_env(env_name: str, n_steps=4, render_mode=None, **kwargs):\n",
        "    print(f\"Creating environment {env_name}\")\n",
        "    env = gym.make(env_name, render_mode=render_mode, **kwargs)\n",
        "    env = atari_wrappers.AtariWrapper(env, clip_reward=False, noop_max=0)\n",
        "    env = ImageToPyTorch(env)\n",
        "    env = BufferWrapper(env, n_steps=n_steps)\n",
        "    return env"
      ],
      "metadata": {
        "id": "Vk2CtGcOBcQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b53c42-d8c9-4bda-fe33-2101d0942bc7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Configuration\n",
        "DEFAULT_ENV_NAME = \"ALE/Breakout-v5\"\n",
        "MEAN_REWARD_BOUND = 5\n",
        "\n",
        "\n",
        "GAMMA = 0.99\n",
        "BATCH_SIZE = 32\n",
        "REPLAY_SIZE = 10000\n",
        "LEARNING_RATE = 1e-4\n",
        "SYNC_TARGET_FRAMES = 1000\n",
        "REPLAY_START_SIZE = 10000\n",
        "\n",
        "SAVE_EPSILON = 0.5  # Only save if at least this much better\n",
        "EPSILON_DECAY_LAST_FRAME = 150000\n",
        "EPSILON_START = 1.0\n",
        "EPSILON_FINAL = 0.01\n",
        "\n",
        "# Tuple of tensors returned from a sampled minibatch in replay buffer\n",
        "State = np.ndarray\n",
        "Action = int\n",
        "BatchTensors = tt.Tuple[\n",
        "    torch.ByteTensor,           # current state\n",
        "    torch.LongTensor,           # actions\n",
        "    torch.Tensor,               # rewards\n",
        "    torch.BoolTensor,           # done || trunc\n",
        "    torch.ByteTensor            # next state\n",
        "]"
      ],
      "metadata": {
        "id": "GvXPdjPCBxOd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âš™ï¸ Fast Training Config for Quick Test Run\n",
        "MEAN_REWARD_BOUND = 5\n",
        "REPLAY_START_SIZE = 1000\n",
        "EPSILON_DECAY_LAST_FRAME = 10_000\n",
        "SYNC_TARGET_FRAMES = 500\n",
        "\n",
        "# REPLAY_SIZE = 5000  # optional\n",
        "# BATCH_SIZE = 16     # optional"
      ],
      "metadata": {
        "id": "3FHvHNMrR9Sk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Define directories\n",
        "save_dir_drive = \"/content/drive/MyDrive/PUBLIC/Models\"\n",
        "save_dir_local = \"saved_models\"\n",
        "\n",
        "# Create both directories if they don't exist\n",
        "os.makedirs(save_dir_drive, exist_ok=True)\n",
        "os.makedirs(save_dir_local, exist_ok=True)\n",
        "\n",
        "# Safe model filename\n",
        "env_name = DEFAULT_ENV_NAME\n",
        "safe_env_name = env_name.replace(\"/\", \"_\")"
      ],
      "metadata": {
        "id": "MkILCuT2OhBV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Experience:\n",
        "    state: State\n",
        "    action: Action\n",
        "    reward: float\n",
        "    done_trunc: bool\n",
        "    new_state: State\n",
        "\n",
        "\n",
        "class ExperienceBuffer:\n",
        "    def __init__(self, capacity: int):\n",
        "        self.buffer = collections.deque(maxlen=capacity)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def append(self, experience: Experience):\n",
        "        self.buffer.append(experience)\n",
        "\n",
        "    def sample(self, batch_size: int) -> tt.List[Experience]:\n",
        "        indices = np.random.choice(len(self), batch_size, replace=False)\n",
        "        return [self.buffer[idx] for idx in indices]"
      ],
      "metadata": {
        "id": "uW4Bo-mcB6rc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, env: gym.Env, exp_buffer: ExperienceBuffer):\n",
        "        self.env = env\n",
        "        self.exp_buffer = exp_buffer\n",
        "        self.state: tt.Optional[np.ndarray] = None\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self):\n",
        "        self.state, _ = self.env.reset()\n",
        "        self.total_reward = 0.0\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def play_step(self, net: DQN, device: torch.device,\n",
        "                  epsilon: float = 0.0) -> tt.Optional[float]:\n",
        "        done_reward = None\n",
        "\n",
        "        if np.random.random() < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            state_v = torch.as_tensor(self.state).to(device)\n",
        "            state_v.unsqueeze_(0)\n",
        "            q_vals_v = net(state_v)\n",
        "            _, act_v = torch.max(q_vals_v, dim=1)\n",
        "            action = int(act_v.item())\n",
        "\n",
        "        # do step in the environment\n",
        "        new_state, reward, is_done, is_tr, _ = self.env.step(action)\n",
        "        self.total_reward += reward\n",
        "\n",
        "        exp = Experience(\n",
        "            state=self.state, action=action, reward=float(reward),\n",
        "            done_trunc=is_done or is_tr, new_state=new_state\n",
        "        )\n",
        "        self.exp_buffer.append(exp)\n",
        "        self.state = new_state\n",
        "        if is_done or is_tr:\n",
        "            done_reward = self.total_reward\n",
        "            self._reset()\n",
        "        return done_reward"
      ],
      "metadata": {
        "id": "irJb4V32B-R8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_to_tensors(batch: tt.List[Experience], device: torch.device) -> BatchTensors:\n",
        "    states, actions, rewards, dones, new_state = [], [], [], [], []\n",
        "    for e in batch:\n",
        "        states.append(e.state)\n",
        "        actions.append(e.action)\n",
        "        rewards.append(e.reward)\n",
        "        dones.append(e.done_trunc)\n",
        "        new_state.append(e.new_state)\n",
        "    states_t = torch.as_tensor(np.asarray(states))\n",
        "    actions_t = torch.LongTensor(actions)\n",
        "    rewards_t = torch.FloatTensor(rewards)\n",
        "    dones_t = torch.BoolTensor(dones)\n",
        "    new_states_t = torch.as_tensor(np.asarray(new_state))\n",
        "    return states_t.to(device), actions_t.to(device), rewards_t.to(device), \\\n",
        "           dones_t.to(device),  new_states_t.to(device)"
      ],
      "metadata": {
        "id": "vHXmNr_wCBJm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(batch: tt.List[Experience], net: DQN, tgt_net: DQN,\n",
        "              device: torch.device) -> torch.Tensor:\n",
        "    states_t, actions_t, rewards_t, dones_t, new_states_t = batch_to_tensors(batch, device)\n",
        "\n",
        "    state_action_values = net(states_t).gather(\n",
        "        1, actions_t.unsqueeze(-1)\n",
        "    ).squeeze(-1)\n",
        "    with torch.no_grad():\n",
        "        next_state_values = tgt_net(new_states_t).max(1)[0]\n",
        "        next_state_values[dones_t] = 0.0\n",
        "        next_state_values = next_state_values.detach()\n",
        "\n",
        "    expected_state_action_values = next_state_values * GAMMA + rewards_t\n",
        "    return nn.MSELoss()(state_action_values, expected_state_action_values)"
      ],
      "metadata": {
        "id": "-dbh0431CEXO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_comment = f\"test_epsdec{EPSILON_DECAY_LAST_FRAME}_rs{REPLAY_START_SIZE}_sync{SYNC_TARGET_FRAMES}\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "env = make_env(env_name)\n",
        "net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "tgt_net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "writer = SummaryWriter(comment=f\"-{env_name}-{model_comment}\")\n",
        "print(net)\n",
        "\n",
        "buffer = ExperienceBuffer(REPLAY_SIZE)\n",
        "agent = Agent(env, buffer)\n",
        "epsilon = EPSILON_START\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "total_rewards = []\n",
        "frame_idx = 0\n",
        "ts_frame = 0\n",
        "ts = time.time()\n",
        "best_m_reward = None\n",
        "\n",
        "MAX_FRAMES = 300000\n",
        "\n",
        "start_time = time.time()\n",
        "while True:\n",
        "    frame_idx += 1\n",
        "\n",
        "    # << NEW STOP CONDITION >>\n",
        "    if frame_idx >= MAX_FRAMES:\n",
        "        print(f\"Reached MAX_FRAMES = {MAX_FRAMES}. Stopping.\")\n",
        "        break\n",
        "\n",
        "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)\n",
        "\n",
        "    reward = agent.play_step(net, device, epsilon)\n",
        "    if reward is not None:\n",
        "        total_rewards.append(reward)\n",
        "        speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
        "        elapsed = time.time() - start_time\n",
        "        ts_frame = frame_idx\n",
        "        ts = time.time()\n",
        "        m_reward = np.mean(total_rewards[-100:])\n",
        "\n",
        "        writer.add_scalar(\"epsilon\", epsilon, frame_idx)\n",
        "        writer.add_scalar(\"speed\", speed, frame_idx)\n",
        "        writer.add_scalar(\"reward_100\", m_reward, frame_idx)\n",
        "        writer.add_scalar(\"reward\", reward, frame_idx)\n",
        "\n",
        "        if best_m_reward is None or m_reward > best_m_reward + SAVE_EPSILON:\n",
        "            print(f\"{frame_idx}: done {len(total_rewards)} games, reward {m_reward:.3f}, \"\n",
        "                  f\"eps {epsilon:.2f}, speed {speed:.2f} f/s, time {elapsed/60:.1f} min\")\n",
        "\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
        "            model_filename = f\"{safe_env_name}-best_{int(m_reward)}-{timestamp}-{model_comment}.dat\"\n",
        "\n",
        "            model_path_drive = os.path.join(save_dir_drive, model_filename)\n",
        "            model_path_local = os.path.join(save_dir_local, model_filename)\n",
        "\n",
        "            torch.save(net.state_dict(), model_path_drive)\n",
        "            torch.save(net.state_dict(), model_path_local)\n",
        "\n",
        "            print(f\"ðŸ’¾ Model saved:\\n - {model_path_drive}\\n - {model_path_local}\")\n",
        "\n",
        "            best_m_reward = m_reward\n",
        "\n",
        "        if m_reward > MEAN_REWARD_BOUND:\n",
        "            print(\"Solved in %d frames!\" % frame_idx)\n",
        "            break\n",
        "\n",
        "    if len(buffer) < REPLAY_START_SIZE:\n",
        "        continue\n",
        "\n",
        "    if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
        "        tgt_net.load_state_dict(net.state_dict())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    batch = buffer.sample(BATCH_SIZE)\n",
        "    loss_t = calc_loss(batch, net, tgt_net, device)\n",
        "    loss_t.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "env.close()\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q8gj-5woCXEB",
        "outputId": "6936e118-cbe2-42d3-cc1c-41f5fbbed27a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating environment ALE/Breakout-v5\n",
            "DQN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "5: done 1 games, reward 0.000, eps 1.00, speed 176.89 f/s, time 0.0 min\n",
            "ðŸ’¾ Model saved:\n",
            " - /content/drive/MyDrive/PUBLIC/Models/ALE_Breakout-v5-best_0-20251202-2239-test_epsdec10000_rs1000_sync500.dat\n",
            " - saved_models/ALE_Breakout-v5-best_0-20251202-2239-test_epsdec10000_rs1000_sync500.dat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6093: done 720 games, reward 0.510, eps 0.39, speed 109.49 f/s, time 1.1 min\n",
            "ðŸ’¾ Model saved:\n",
            " - /content/drive/MyDrive/PUBLIC/Models/ALE_Breakout-v5-best_0-20251202-2240-test_epsdec10000_rs1000_sync500.dat\n",
            " - saved_models/ALE_Breakout-v5-best_0-20251202-2240-test_epsdec10000_rs1000_sync500.dat\n",
            "7628: done 834 games, reward 1.020, eps 0.24, speed 104.76 f/s, time 1.4 min\n",
            "ðŸ’¾ Model saved:\n",
            " - /content/drive/MyDrive/PUBLIC/Models/ALE_Breakout-v5-best_1-20251202-2241-test_epsdec10000_rs1000_sync500.dat\n",
            " - saved_models/ALE_Breakout-v5-best_1-20251202-2241-test_epsdec10000_rs1000_sync500.dat\n",
            "9791: done 963 games, reward 1.550, eps 0.02, speed 104.96 f/s, time 1.8 min\n",
            "ðŸ’¾ Model saved:\n",
            " - /content/drive/MyDrive/PUBLIC/Models/ALE_Breakout-v5-best_1-20251202-2241-test_epsdec10000_rs1000_sync500.dat\n",
            " - saved_models/ALE_Breakout-v5-best_1-20251202-2241-test_epsdec10000_rs1000_sync500.dat\n",
            "11010: done 1016 games, reward 2.070, eps 0.01, speed 104.38 f/s, time 2.0 min\n",
            "ðŸ’¾ Model saved:\n",
            " - /content/drive/MyDrive/PUBLIC/Models/ALE_Breakout-v5-best_2-20251202-2241-test_epsdec10000_rs1000_sync500.dat\n",
            " - saved_models/ALE_Breakout-v5-best_2-20251202-2241-test_epsdec10000_rs1000_sync500.dat\n",
            "34131: done 2101 games, reward 2.580, eps 0.01, speed 100.26 f/s, time 6.4 min\n",
            "ðŸ’¾ Model saved:\n",
            " - /content/drive/MyDrive/PUBLIC/Models/ALE_Breakout-v5-best_2-20251202-2246-test_epsdec10000_rs1000_sync500.dat\n",
            " - saved_models/ALE_Breakout-v5-best_2-20251202-2246-test_epsdec10000_rs1000_sync500.dat\n",
            "41734: done 2391 games, reward 3.110, eps 0.01, speed 103.90 f/s, time 7.8 min\n",
            "ðŸ’¾ Model saved:\n",
            " - /content/drive/MyDrive/PUBLIC/Models/ALE_Breakout-v5-best_3-20251202-2247-test_epsdec10000_rs1000_sync500.dat\n",
            " - saved_models/ALE_Breakout-v5-best_3-20251202-2247-test_epsdec10000_rs1000_sync500.dat\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1320068184.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mloss_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mloss_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, numpy as np, torch, imageio.v2 as imageio\n",
        "\n",
        "def record_episode_video(policy_net, eps, seconds, fps, out_path):\n",
        "    target_frames = int(seconds * fps)\n",
        "    frames = []\n",
        "    env = make_env(DEFAULT_ENV_NAME, render_mode=\"rgb_array\")\n",
        "    device = next(policy_net.parameters()).device\n",
        "    rng = np.random.RandomState(0)\n",
        "\n",
        "    while len(frames) < target_frames:\n",
        "        state, _ = env.reset(seed=int(rng.randint(0, 1_000_000)))\n",
        "        done = False\n",
        "        trunc = False\n",
        "\n",
        "        while not (done or trunc) and len(frames) < target_frames:\n",
        "            if rng.rand() < eps:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    s_v = torch.as_tensor(state, device=device).unsqueeze(0)\n",
        "                    q_vals = policy_net(s_v)\n",
        "                    action = int(q_vals.argmax(dim=1).item())\n",
        "\n",
        "            next_state, reward, done, trunc, _ = env.step(action)\n",
        "            frame = env.render()\n",
        "            if frame is not None:\n",
        "                frames.append(frame)\n",
        "            state = next_state\n",
        "\n",
        "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "    imageio.mimsave(out_path, frames, fps=fps)\n",
        "    env.close()\n",
        "    print(\"saved:\", out_path, \"frames:\", len(frames))\n",
        "\n",
        "tmp_env = make_env(DEFAULT_ENV_NAME)\n",
        "early_net = DQN(tmp_env.observation_space.shape, tmp_env.action_space.n).to(device)\n",
        "tmp_env.close()\n",
        "\n",
        "record_episode_video(early_net, eps=1.0, seconds=5, fps=15, out_path=\"videos/early.mp4\")\n",
        "record_episode_video(net,      eps=0.05, seconds=5, fps=15, out_path=\"videos/later.mp4\")\n"
      ],
      "metadata": {
        "id": "ZFH6nOSRETHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5300c893-ff6a-47b3-ee22-a4b6949877b6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating environment ALE/Breakout-v5\n",
            "Creating environment ALE/Breakout-v5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved: videos/early.mp4 frames: 75\n",
            "Creating environment ALE/Breakout-v5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved: videos/later.mp4 frames: 75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh videos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXPzTWBxRHsf",
        "outputId": "204cbc46-1b6b-4ec8-f065-fac434ee868d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 20K\n",
            "-rw-r--r-- 1 root root 7.9K Dec  2 22:57 early.mp4\n",
            "-rw-r--r-- 1 root root 8.5K Dec  2 22:57 later.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Video, display\n",
        "\n",
        "display(Video(\"videos/early.mp4\", embed=True, width=480))\n",
        "display(Video(\"videos/later.mp4\", embed=True, width=480))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BGcnapcJSa8d",
        "outputId": "9cc3faec-8d15-4f3b-f839-ccd8a09f1dd9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video controls  width=\"480\" >\n",
              " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video controls  width=\"480\" >\n",
              " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}